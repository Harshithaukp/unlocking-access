{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzFuZL8_l_qd",
        "outputId": "78b9d249-a9a2-476e-d755-1db79865831d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.7.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=f2bd3d0f54dda21ddab36d1d7e6a48f13f9225c1e67b85aa1cb41b40adf6a477\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20250625\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Collecting click<8.2,>=7.1 (from gTTS)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.7.14)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: click, gTTS\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "Successfully installed click-8.1.8 gTTS-2.5.4\n",
            "Collecting twilio\n",
            "  Downloading twilio-9.7.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.32.3)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from twilio) (2.10.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.11/dist-packages (from twilio) (3.11.15)\n",
            "Collecting aiohttp-retry>=2.8.3 (from twilio)\n",
            "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.4->twilio) (1.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->twilio) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp>=3.8.4->twilio) (4.14.1)\n",
            "Downloading twilio-9.7.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: aiohttp-retry, twilio\n",
            "Successfully installed aiohttp-retry-2.9.1 twilio-9.7.0\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "âœ… All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install all required packages\n",
        "!pip install gradio\n",
        "!pip install openai-whisper\n",
        "!pip install gTTS\n",
        "!pip install twilio\n",
        "!pip install pydub\n",
        "!pip install python-dotenv\n",
        "!pip install requests\n",
        "\n",
        "# Import all libraries\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import os\n",
        "import tempfile\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "import json\n",
        "from gtts import gTTS\n",
        "from twilio.rest import Client\n",
        "import re\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "import base64\n",
        "\n",
        "print(\"âœ… All packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete welfare schemes database\n",
        "WELFARE_SCHEMES = {\n",
        "    'pmay': {\n",
        "        'name': 'Pradhan Mantri Awas Yojana (PM-AY)',\n",
        "        'description': 'Housing scheme for economically weaker sections',\n",
        "        'eligibility': 'Annual income below â‚¹3-6 lakh, no pucca house',\n",
        "        'benefits': 'Subsidy up to â‚¹2.67 lakh for house construction',\n",
        "        'keywords': ['house', 'housing', 'home', 'shelter', 'construction', 'à¤—à¥ƒà¤¹', 'à¤®à¤•à¤¾à¤¨', 'à¤†à¤µà¤¾à¤¸'],\n",
        "        'categories': ['housing', 'urban', 'rural']\n",
        "    },\n",
        "    'ujjwala': {\n",
        "        'name': 'PM Ujjwala Yojana',\n",
        "        'description': 'Free LPG connection for women from BPL families',\n",
        "        'eligibility': 'BPL family, woman as beneficiary',\n",
        "        'benefits': 'Free LPG connection + â‚¹1600 deposit',\n",
        "        'keywords': ['gas', 'lpg', 'cooking', 'fuel', 'cylinder', 'à¤—à¥ˆà¤¸', 'à¤°à¤¸à¥‹à¤ˆ', 'à¤–à¤¾à¤¨à¤¾'],\n",
        "        'categories': ['fuel', 'women', 'cooking']\n",
        "    },\n",
        "    'pmkisan': {\n",
        "        'name': 'PM-KISAN Samman Nidhi',\n",
        "        'description': 'Income support for small farmer families',\n",
        "        'eligibility': 'Small & marginal farmers with cultivable land',\n",
        "        'benefits': 'â‚¹6000 per year in 3 installments',\n",
        "        'keywords': ['farmer', 'agriculture', 'farming', 'crop', 'land', 'à¤•à¤¿à¤¸à¤¾à¤¨', 'à¤–à¥‡à¤¤à¥€', 'à¤«à¤¸à¤²'],\n",
        "        'categories': ['agriculture', 'farming', 'income']\n",
        "    },\n",
        "    'ayushman': {\n",
        "        'name': 'Ayushman Bharat (PM-JAY)',\n",
        "        'description': 'Health insurance for poor families',\n",
        "        'eligibility': 'Families identified in SECC database',\n",
        "        'benefits': 'Health cover up to â‚¹5 lakh per family per year',\n",
        "        'keywords': ['health', 'medical', 'insurance', 'hospital', 'treatment', 'à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯', 'à¤‡à¤²à¤¾à¤œ', 'à¤¬à¥€à¤®à¤¾'],\n",
        "        'categories': ['health', 'insurance', 'medical']\n",
        "    },\n",
        "    'pension': {\n",
        "        'name': 'National Social Assistance Programme (NSAP)',\n",
        "        'description': 'Pension for elderly, widow, and disabled',\n",
        "        'eligibility': 'Age 60+, widows, persons with disabilities',\n",
        "        'benefits': 'â‚¹200-500 per month pension',\n",
        "        'keywords': ['pension', 'elderly', 'old', 'widow', 'disabled', 'à¤ªà¥‡à¤‚à¤¶à¤¨', 'à¤¬à¥à¤œà¥à¤°à¥à¤—', 'à¤µà¤¿à¤§à¤µà¤¾'],\n",
        "        'categories': ['pension', 'elderly', 'social_security']\n",
        "    },\n",
        "    'scholarship': {\n",
        "        'name': 'Post Matric Scholarship',\n",
        "        'description': 'Educational support for SC/ST students',\n",
        "        'eligibility': 'SC/ST students in post-matric courses',\n",
        "        'benefits': 'Tuition fees + maintenance allowance',\n",
        "        'keywords': ['education', 'study', 'student', 'scholarship', 'school', 'college', 'à¤¶à¤¿à¤•à¥à¤·à¤¾', 'à¤ªà¤¢à¤¼à¤¾à¤ˆ', 'à¤›à¤¾à¤¤à¥à¤°à¤µà¥ƒà¤¤à¥à¤¤à¤¿'],\n",
        "        'categories': ['education', 'student', 'scholarship']\n",
        "    },\n",
        "    'mudra': {\n",
        "        'name': 'Pradhan Mantri MUDRA Yojana',\n",
        "        'description': 'Micro finance loans for small businesses',\n",
        "        'eligibility': 'Micro enterprises, small traders, self-employed',\n",
        "        'benefits': 'Loans up to â‚¹10 lakh without collateral',\n",
        "        'keywords': ['business', 'loan', 'money', 'enterprise', 'trade', 'à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°', 'à¤•à¤¾à¤°à¥‹à¤¬à¤¾à¤°', 'à¤‹à¤£'],\n",
        "        'categories': ['business', 'loan', 'finance']\n",
        "    },\n",
        "    'swachh': {\n",
        "        'name': 'Swachh Bharat Mission',\n",
        "        'description': 'Toilet construction in rural areas',\n",
        "        'eligibility': 'Households without toilets in rural areas',\n",
        "        'benefits': 'â‚¹12,000 incentive for toilet construction',\n",
        "        'keywords': ['toilet', 'sanitation', 'cleanliness', 'bathroom', 'à¤¶à¥Œà¤šà¤¾à¤²à¤¯', 'à¤¸à¥à¤µà¤šà¥à¤›à¤¤à¤¾', 'à¤¸à¤«à¤¾à¤ˆ'],\n",
        "        'categories': ['sanitation', 'rural', 'infrastructure']\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"âœ… Welfare schemes database loaded!\")\n",
        "print(f\"ğŸ“Š Total schemes available: {len(WELFARE_SCHEMES)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8tzfYtsnBMk",
        "outputId": "4975e2f9-0169-402b-b891-af9a2102651f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Welfare schemes database loaded!\n",
            "ğŸ“Š Total schemes available: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Whisper model for speech recognition\n",
        "print(\"ğŸ¤ Loading Whisper model...\")\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "print(\"âœ… Whisper model loaded!\")\n",
        "\n",
        "def transcribe_audio(audio_file_path, language=\"auto\"):\n",
        "    \"\"\"Convert speech to text using Whisper\"\"\"\n",
        "    try:\n",
        "        # Load and transcribe audio\n",
        "        result = whisper_model.transcribe(audio_file_path)\n",
        "\n",
        "        return {\n",
        "            'success': True,\n",
        "            'text': result['text'].strip(),\n",
        "            'language': result.get('language', 'unknown')\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': str(e),\n",
        "            'text': '',\n",
        "            'language': 'unknown'\n",
        "        }\n",
        "\n",
        "def extract_keywords_and_intent(text):\n",
        "    \"\"\"Extract relevant information from user text\"\"\"\n",
        "    text = text.lower()\n",
        "\n",
        "    # Extract potential income\n",
        "    income_match = re.search(r'(\\d+)\\s*(lakh|thousand|à¤¹à¤œà¤¾à¤°|à¤²à¤¾à¤–)', text)\n",
        "    income = None\n",
        "    if income_match:\n",
        "        amount = int(income_match.group(1))\n",
        "        unit = income_match.group(2)\n",
        "        if 'lakh' in unit or 'à¤²à¤¾à¤–' in unit:\n",
        "            income = amount * 100000\n",
        "        else:\n",
        "            income = amount * 1000\n",
        "\n",
        "    # Extract age\n",
        "    age_match = re.search(r'(\\d+)\\s*(year|à¤¸à¤¾à¤²|à¤µà¤°à¥à¤·)', text)\n",
        "    age = int(age_match.group(1)) if age_match else None\n",
        "\n",
        "    # Extract location type\n",
        "    location_type = 'rural' if any(word in text for word in ['village', 'rural', 'à¤—à¤¾à¤‚à¤µ', 'à¤—à¥à¤°à¤¾à¤®à¥€à¤£']) else 'urban'\n",
        "\n",
        "    # Extract gender\n",
        "    gender = None\n",
        "    if any(word in text for word in ['woman', 'female', 'wife', 'mother', 'à¤®à¤¹à¤¿à¤²à¤¾', 'à¤¸à¥à¤¤à¥à¤°à¥€']):\n",
        "        gender = 'female'\n",
        "    elif any(word in text for word in ['man', 'male', 'husband', 'father', 'à¤ªà¥à¤°à¥à¤·', 'à¤†à¤¦à¤®à¥€']):\n",
        "        gender = 'male'\n",
        "\n",
        "    return {\n",
        "        'text': text,\n",
        "        'income': income,\n",
        "        'age': age,\n",
        "        'location_type': location_type,\n",
        "        'gender': gender,\n",
        "        'keywords': text.split()\n",
        "    }\n",
        "\n",
        "def match_welfare_schemes(user_info):\n",
        "    \"\"\"Find matching welfare schemes based on user information\"\"\"\n",
        "    matched_schemes = []\n",
        "\n",
        "    for scheme_id, scheme in WELFARE_SCHEMES.items():\n",
        "        score = 0\n",
        "\n",
        "        # Keyword matching\n",
        "        user_keywords = user_info['keywords']\n",
        "        scheme_keywords = scheme['keywords']\n",
        "\n",
        "        keyword_matches = sum(1 for keyword in scheme_keywords\n",
        "                            if any(uk in keyword or keyword in uk for uk in user_keywords))\n",
        "        score += keyword_matches * 10\n",
        "\n",
        "        # Income-based matching\n",
        "        if user_info['income']:\n",
        "            if scheme_id == 'pmay' and user_info['income'] < 600000:\n",
        "                score += 20\n",
        "            elif scheme_id == 'pmkisan' and user_info['income'] < 200000:\n",
        "                score += 20\n",
        "            elif scheme_id == 'ujjwala' and user_info['income'] < 100000:\n",
        "                score += 20\n",
        "\n",
        "        # Age-based matching\n",
        "        if user_info['age']:\n",
        "            if scheme_id == 'pension' and user_info['age'] >= 60:\n",
        "                score += 30\n",
        "            elif scheme_id == 'scholarship' and 18 <= user_info['age'] <= 25:\n",
        "                score += 25\n",
        "\n",
        "        # Gender-based matching\n",
        "        if user_info['gender'] == 'female' and scheme_id == 'ujjwala':\n",
        "            score += 15\n",
        "\n",
        "        if score > 10:  # Minimum threshold\n",
        "            matched_schemes.append({\n",
        "                'id': scheme_id,\n",
        "                'score': score,\n",
        "                **scheme\n",
        "            })\n",
        "\n",
        "    # Sort by score and return top matches\n",
        "    matched_schemes.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return matched_schemes[:3]  # Return top 3 matches\n",
        "\n",
        "def generate_response_text(schemes, language=\"hi\"):\n",
        "    \"\"\"Generate appropriate response text\"\"\"\n",
        "    if not schemes:\n",
        "        if language == \"hi\":\n",
        "            return \"à¤–à¥à¤¶à¥€ à¤•à¥€ à¤¬à¤¾à¤¤ à¤¹à¥ˆ à¤•à¤¿ à¤†à¤ªà¤¨à¥‡ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤¿à¤¯à¤¾à¥¤ à¤…à¤­à¥€ à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤•à¥‹à¤ˆ à¤µà¤¿à¤¶à¥‡à¤· à¤¯à¥‹à¤œà¤¨à¤¾ à¤¨à¤¹à¥€à¤‚ à¤®à¤¿à¤²à¥€, à¤²à¥‡à¤•à¤¿à¤¨ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¥€ à¤œà¤°à¥‚à¤°à¤¤à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤”à¤° à¤¬à¤¤à¤¾à¤à¤‚à¥¤\"\n",
        "        else:\n",
        "            return \"Thank you for your inquiry. I couldn't find specific schemes matching your needs right now. Please provide more details about your requirements.\"\n",
        "\n",
        "    if language == \"hi\":\n",
        "        if len(schemes) == 1:\n",
        "            return f\"à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤¯à¥‹à¤œà¤¨à¤¾ à¤®à¤¿à¤²à¥€ à¤¹à¥ˆ: {schemes[0]['name']}à¥¤ {schemes[0]['description']}à¥¤ à¤…à¤§à¤¿à¤• à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¨à¥€à¤šà¥‡ à¤¦à¥€ à¤—à¤ˆ à¤¹à¥ˆà¥¤\"\n",
        "        else:\n",
        "            scheme_names = \", \".join([s['name'] for s in schemes])\n",
        "            return f\"à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ {len(schemes)} à¤¯à¥‹à¤œà¤¨à¤¾à¤à¤‚ à¤®à¤¿à¤²à¥€ à¤¹à¥ˆà¤‚: {scheme_names}à¥¤ à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¨à¥€à¤šà¥‡ à¤¦à¥€ à¤—à¤ˆ à¤¹à¥ˆà¥¤\"\n",
        "    else:\n",
        "        if len(schemes) == 1:\n",
        "            return f\"I found one scheme for you: {schemes[0]['name']}. {schemes[0]['description']}. Details are provided below.\"\n",
        "        else:\n",
        "            scheme_names = \", \".join([s['name'] for s in schemes])\n",
        "            return f\"I found {len(schemes)} schemes for you: {scheme_names}. Detailed information is provided below.\"\n",
        "\n",
        "def text_to_speech(text, language=\"hi\"):\n",
        "    \"\"\"Convert text to speech using gTTS\"\"\"\n",
        "    try:\n",
        "        # Map language codes\n",
        "        lang_code = \"hi\" if language == \"hi\" else \"en\"\n",
        "\n",
        "        # Generate TTS\n",
        "        tts = gTTS(text=text, lang=lang_code, slow=False)\n",
        "\n",
        "        # Save to temporary file\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "        tts.save(temp_file.name)\n",
        "\n",
        "        return {\n",
        "            'success': True,\n",
        "            'file_path': temp_file.name\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': str(e),\n",
        "            'file_path': None\n",
        "        }\n",
        "\n",
        "print(\"âœ… AI processing functions ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I56pTzcWnG0T",
        "outputId": "4f2e7034-f4d1-4461-a038-f180b4c1f09b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¤ Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:01<00:00, 107MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Whisper model loaded!\n",
            "âœ… AI processing functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Twilio SMS setup (optional - set your credentials)\n",
        "TWILIO_ACCOUNT_SID = \"\"  # Add your Twilio Account SID\n",
        "TWILIO_AUTH_TOKEN = \"\"   # Add your Twilio Auth Token\n",
        "TWILIO_PHONE_NUMBER = \"\" # Add your Twilio phone number\n",
        "\n",
        "def send_sms(phone_number, message):\n",
        "    \"\"\"Send SMS via Twilio (if credentials are provided)\"\"\"\n",
        "    if not all([TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, TWILIO_PHONE_NUMBER]):\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': 'SMS credentials not configured',\n",
        "            'message': 'SMS functionality disabled - no Twilio credentials'\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
        "        message = client.messages.create(\n",
        "            body=message,\n",
        "            from_=TWILIO_PHONE_NUMBER,\n",
        "            to=phone_number\n",
        "        )\n",
        "        return {\n",
        "            'success': True,\n",
        "            'message_sid': message.sid,\n",
        "            'message': 'SMS sent successfully'\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'error': str(e),\n",
        "            'message': 'Failed to send SMS'\n",
        "        }\n",
        "\n",
        "def generate_sms_text(schemes, language=\"hi\"):\n",
        "    \"\"\"Generate SMS text with scheme details\"\"\"\n",
        "    if language == \"hi\":\n",
        "        sms = \"ğŸ›ï¸ à¤†à¤ªà¤•à¥€ à¤¯à¥‹à¤œà¤¨à¤¾à¤à¤‚:\\n\\n\"\n",
        "        for i, scheme in enumerate(schemes, 1):\n",
        "            sms += f\"{i}. {scheme['name']}\\n\"\n",
        "            sms += f\"   ğŸ“‹ à¤ªà¤¾à¤¤à¥à¤°à¤¤à¤¾: {scheme['eligibility']}\\n\"\n",
        "            sms += f\"   ğŸ’° à¤²à¤¾à¤­: {scheme['benefits']}\\n\\n\"\n",
        "        sms += \"à¤…à¤§à¤¿à¤• à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¤œà¤¦à¥€à¤•à¥€ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤•à¤¾à¤°à¥à¤¯à¤¾à¤²à¤¯ à¤®à¥‡à¤‚ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤°à¥‡à¤‚à¥¤\"\n",
        "    else:\n",
        "        sms = \"ğŸ›ï¸ Your Eligible Schemes:\\n\\n\"\n",
        "        for i, scheme in enumerate(schemes, 1):\n",
        "            sms += f\"{i}. {scheme['name']}\\n\"\n",
        "            sms += f\"   ğŸ“‹ Eligibility: {scheme['eligibility']}\\n\"\n",
        "            sms += f\"   ğŸ’° Benefits: {scheme['benefits']}\\n\\n\"\n",
        "        sms += \"For more information, contact your nearest government office.\"\n",
        "\n",
        "    return sms\n",
        "\n",
        "print(\"âœ… SMS integration ready! (Configure Twilio credentials to enable)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvJmjvNHnMPL",
        "outputId": "35bf8f25-3d9d-449e-9ca3-7b081b23cdbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SMS integration ready! (Configure Twilio credentials to enable)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_voice_query(audio_file, phone_number=\"\", language_preference=\"auto\"):\n",
        "    \"\"\"Main function to process voice query and return welfare scheme information\"\"\"\n",
        "\n",
        "    session_id = str(uuid.uuid4())[:8]\n",
        "    processing_log = []\n",
        "\n",
        "    try:\n",
        "        # Step 1: Speech to Text\n",
        "        processing_log.append(\"ğŸ¤ Converting speech to text...\")\n",
        "\n",
        "        if audio_file is None:\n",
        "            return \"âŒ Please upload an audio file\", \"\", [], None, \"No audio file provided\"\n",
        "\n",
        "        transcription_result = transcribe_audio(audio_file)\n",
        "\n",
        "        if not transcription_result['success']:\n",
        "            return f\"âŒ Speech recognition failed: {transcription_result['error']}\", \"\", [], None, \"\\n\".join(processing_log)\n",
        "\n",
        "        transcribed_text = transcription_result['text']\n",
        "        detected_language = transcription_result['language']\n",
        "\n",
        "        processing_log.append(f\"âœ… Transcribed: '{transcribed_text}'\")\n",
        "        processing_log.append(f\"ğŸŒ Language detected: {detected_language}\")\n",
        "\n",
        "        # Step 2: Extract information\n",
        "        processing_log.append(\"ğŸ§  Analyzing your requirements...\")\n",
        "        user_info = extract_keywords_and_intent(transcribed_text)\n",
        "\n",
        "        # Step 3: Match schemes\n",
        "        processing_log.append(\"ğŸ” Finding matching welfare schemes...\")\n",
        "        matching_schemes = match_welfare_schemes(user_info)\n",
        "\n",
        "        processing_log.append(f\"âœ… Found {len(matching_schemes)} matching schemes\")\n",
        "\n",
        "        # Step 4: Generate response\n",
        "        response_text = generate_response_text(matching_schemes, detected_language)\n",
        "\n",
        "        # Step 5: Generate TTS\n",
        "        processing_log.append(\"ğŸ”Š Generating voice response...\")\n",
        "        tts_result = text_to_speech(response_text, detected_language)\n",
        "\n",
        "        tts_audio_file = None\n",
        "        if tts_result['success']:\n",
        "            tts_audio_file = tts_result['file_path']\n",
        "            processing_log.append(\"âœ… Voice response generated\")\n",
        "        else:\n",
        "            processing_log.append(f\"âš ï¸ TTS failed: {tts_result['error']}\")\n",
        "\n",
        "        # Step 6: Send SMS (if phone number provided)\n",
        "        sms_status = \"\"\n",
        "        if phone_number.strip():\n",
        "            processing_log.append(\"ğŸ“± Sending SMS with detailed information...\")\n",
        "            sms_text = generate_sms_text(matching_schemes, detected_language)\n",
        "            sms_result = send_sms(phone_number, sms_text)\n",
        "            if sms_result['success']:\n",
        "                sms_status = \"âœ… SMS sent successfully\"\n",
        "            else:\n",
        "                sms_status = f\"âš ï¸ SMS failed: {sms_result['message']}\"\n",
        "            processing_log.append(sms_status)\n",
        "\n",
        "        # Format schemes for display\n",
        "        schemes_display = []\n",
        "        for scheme in matching_schemes:\n",
        "            schemes_display.append({\n",
        "                \"name\": scheme['name'],\n",
        "                \"description\": scheme['description'],\n",
        "                \"eligibility\": scheme['eligibility'],\n",
        "                \"benefits\": scheme['benefits'],\n",
        "                \"relevance_score\": f\"{scheme['score']}/100\"\n",
        "            })\n",
        "\n",
        "        return (\n",
        "            response_text,\n",
        "            transcribed_text,\n",
        "            schemes_display,\n",
        "            tts_audio_file,\n",
        "            \"\\n\".join(processing_log) + f\"\\n\\n{sms_status}\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Error processing request: {str(e)}\"\n",
        "        processing_log.append(error_msg)\n",
        "        return error_msg, \"\", [], None, \"\\n\".join(processing_log)\n",
        "\n",
        "def process_text_query(text_input, phone_number=\"\", language_preference=\"hi\"):\n",
        "    \"\"\"Process text query directly (for testing without audio)\"\"\"\n",
        "\n",
        "    session_id = str(uuid.uuid4())[:8]\n",
        "    processing_log = []\n",
        "\n",
        "    try:\n",
        "        if not text_input.strip():\n",
        "            return \"âŒ Please enter your query\", \"\", [], None, \"No text input provided\"\n",
        "\n",
        "        processing_log.append(f\"ğŸ“ Processing text: '{text_input}'\")\n",
        "\n",
        "        # Extract information\n",
        "        user_info = extract_keywords_and_intent(text_input)\n",
        "        processing_log.append(\"ğŸ§  Analyzing your requirements...\")\n",
        "\n",
        "        # Match schemes\n",
        "        matching_schemes = match_welfare_schemes(user_info)\n",
        "        processing_log.append(f\"âœ… Found {len(matching_schemes)} matching schemes\")\n",
        "\n",
        "        # Generate response\n",
        "        response_text = generate_response_text(matching_schemes, language_preference)\n",
        "\n",
        "        # Generate TTS\n",
        "        processing_log.append(\"ğŸ”Š Generating voice response...\")\n",
        "        tts_result = text_to_speech(response_text, language_preference)\n",
        "\n",
        "        tts_audio_file = None\n",
        "        if tts_result['success']:\n",
        "            tts_audio_file = tts_result['file_path']\n",
        "            processing_log.append(\"âœ… Voice response generated\")\n",
        "\n",
        "        # Send SMS (if phone number provided)\n",
        "        sms_status = \"\"\n",
        "        if phone_number.strip():\n",
        "            processing_log.append(\"ğŸ“± Sending SMS...\")\n",
        "            sms_text = generate_sms_text(matching_schemes, language_preference)\n",
        "            sms_result = send_sms(phone_number, sms_text)\n",
        "            sms_status = \"âœ… SMS sent\" if sms_result['success'] else f\"âš ï¸ SMS failed: {sms_result['message']}\"\n",
        "            processing_log.append(sms_status)\n",
        "\n",
        "        # Format schemes for display\n",
        "        schemes_display = []\n",
        "        for scheme in matching_schemes:\n",
        "            schemes_display.append({\n",
        "                \"name\": scheme['name'],\n",
        "                \"description\": scheme['description'],\n",
        "                \"eligibility\": scheme['eligibility'],\n",
        "                \"benefits\": scheme['benefits'],\n",
        "                \"relevance_score\": f\"{scheme['score']}/100\"\n",
        "            })\n",
        "\n",
        "        return (\n",
        "            response_text,\n",
        "            text_input,\n",
        "            schemes_display,\n",
        "            tts_audio_file,\n",
        "            \"\\n\".join(processing_log) + f\"\\n\\n{sms_status}\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Error: {str(e)}\"\n",
        "        processing_log.append(error_msg)\n",
        "        return error_msg, \"\", [], None, \"\\n\".join(processing_log)\n",
        "\n",
        "print(\"âœ… Main processing functions ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmVIMqIinoIk",
        "outputId": "eb55d173-aed3-4d72-c632-34e6c2e556bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Main processing functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Gradio web interface\n",
        "def create_interface():\n",
        "\n",
        "    with gr.Blocks(title=\"Unlocking Access - Voice-First Welfare Assistant\", theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        # Unlocking Access - Voice-First AI Platform for Social Welfare\n",
        "        ### Hack-A-Tone 2025 MVP Demo\n",
        "\n",
        "        **How it works:**\n",
        "        1.  Upload audio file OR type your query\n",
        "        2.  AI processes and matches welfare schemes\n",
        "        3.  Get voice response + detailed information\n",
        "        4.  Optional SMS with complete details\n",
        "\n",
        "        **Languages Supported:** Hindi, English, and mixed (Hinglish)\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tab(\" Voice Query\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    audio_input = gr.Audio(\n",
        "                        sources=[\"microphone\", \"upload\"],\n",
        "                        type=\"filepath\",\n",
        "                        label=\"Record or Upload Audio Query\"\n",
        "                    )\n",
        "                    phone_input_voice = gr.Textbox(\n",
        "                        label=\" Phone Number (Optional)\",\n",
        "                        placeholder=\"+91 1234567891\",\n",
        "                        info=\"Enter phone number to receive SMS with detailed scheme information\"\n",
        "                    )\n",
        "                    lang_voice = gr.Dropdown(\n",
        "                        choices=[\"auto\", \"hi\", \"en\"],\n",
        "                        value=\"auto\",\n",
        "                        label=\"Language Preference\"\n",
        "                    )\n",
        "                    process_voice_btn = gr.Button(\"Process Voice Query\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    response_voice = gr.Textbox(label=\" AI Response\", lines=4)\n",
        "                    transcription_voice = gr.Textbox(label=\"What You Said\", lines=2)\n",
        "                    audio_response_voice = gr.Audio(label=\" Voice Response\")\n",
        "\n",
        "        with gr.Tab(\" Text Query\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    text_input = gr.Textbox(\n",
        "                        label=\"Type Your Query\",\n",
        "                        lines=3,\n",
        "                        placeholder=\"Example: à¤®à¥à¤à¥‡ à¤˜à¤° à¤¬à¤¨à¤¾à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤¯à¥‹à¤œà¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤ (I need government scheme for house construction)\"\n",
        "                    )\n",
        "                    phone_input_text = gr.Textbox(\n",
        "                        label=\" Phone Number (Optional)\",\n",
        "                        placeholder=\"+919876543210\"\n",
        "                    )\n",
        "                    lang_text = gr.Dropdown(\n",
        "                        choices=[\"hi\", \"en\"],\n",
        "                        value=\"hi\",\n",
        "                        label=\" Response Language\"\n",
        "                    )\n",
        "                    process_text_btn = gr.Button(\" Process Text Query\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    response_text = gr.Textbox(label=\" AI Response\", lines=4)\n",
        "                    echo_text = gr.Textbox(label=\" Your Query\", lines=2)\n",
        "                    audio_response_text = gr.Audio(label=\" Voice Response\")\n",
        "\n",
        "        # Shared outputs\n",
        "        with gr.Row():\n",
        "            schemes_output = gr.JSON(label=\"Matched Welfare Schemes\", visible=True)\n",
        "\n",
        "        with gr.Row():\n",
        "            processing_log = gr.Textbox(label=\" Processing Log\", lines=8, max_lines=10)\n",
        "\n",
        "        # Event handlers\n",
        "        process_voice_btn.click(\n",
        "            fn=process_voice_query,\n",
        "            inputs=[audio_input, phone_input_voice, lang_voice],\n",
        "            outputs=[response_voice, transcription_voice, schemes_output, audio_response_voice, processing_log]\n",
        "        )\n",
        "\n",
        "        process_text_btn.click(\n",
        "            fn=process_text_query,\n",
        "            inputs=[text_input, phone_input_text, lang_text],\n",
        "            outputs=[response_text, echo_text, schemes_output, audio_response_text, processing_log]\n",
        "        )\n",
        "\n",
        "        # Example queries\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### Sample Queries to Try:\n",
        "\n",
        "        **Hindi Examples:**\n",
        "        - à¤®à¥à¤à¥‡ à¤˜à¤° à¤¬à¤¨à¤¾à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¯à¥‹à¤œà¤¨à¤¾ à¤šà¤¾à¤¹à¤¿à¤ (I need scheme for house construction)\n",
        "        - à¤•à¤¿à¤¸à¤¾à¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¥à¤¯à¤¾ à¤¯à¥‹à¤œà¤¨à¤¾ à¤¹à¥ˆ (What schemes for farmers)\n",
        "        - à¤¬à¥à¤œà¥à¤°à¥à¤—à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥‡à¤‚à¤¶à¤¨ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ (Pension information for elderly)\n",
        "        - à¤®à¤¹à¤¿à¤²à¤¾ à¤•à¥‡ à¤²à¤¿à¤ à¤—à¥ˆà¤¸ à¤•à¤¨à¥‡à¤•à¥à¤¶à¤¨ (Gas connection for women)\n",
        "\n",
        "        **English Examples:**\n",
        "        - I need financial help for my small business\n",
        "        - What health insurance schemes are available\n",
        "        - Education scholarship for my daughter\n",
        "        - I am 65 years old and need pension information\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "demo = create_interface()\n",
        "print(\"Starting Gradio interface...\")\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "T2zcYxJXnsVz",
        "outputId": "79c57228-921d-4fe1-cacc-bbedb7451e6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Gradio interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2843d4ad9835ff6cb0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2843d4ad9835ff6cb0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2843d4ad9835ff6cb0.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}